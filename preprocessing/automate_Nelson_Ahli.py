# -*- coding: utf-8 -*-
"""automate_Nelson-Ahli

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ceOomnlzCQP6Cqk39zRp_oivIPK4Zw8M
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, OrdinalEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split

from google.colab import files
from joblib import dump
import os

def preprocess_data(data, target_column, save_path, file_path, final_dataset_path):
    data = data.copy()
    data = data.drop_duplicates()

    data = data.drop(['customerID'], axis=1)
    data['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')

    numeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges']
    categorical_features = data.select_dtypes(include=['object']).columns.tolist()
    ordinal_features = ['Churn', 'tenure_binning']

    column_names = data.columns
    column_names = data.columns.drop(target_column)

    df_header = pd.DataFrame(columns=column_names)

    df_header.to_csv(file_path, index=False)
    print(f"Nama kolom berhasil disimpan ke: {file_path}")

    if target_column in numeric_features:
        numeric_features.remove(target_column)
    if target_column in categorical_features:
        categorical_features.remove(target_column)

    data[numeric_features] = data[numeric_features].fillna(data[numeric_features].median())

    binnings = [0, 12, 24, 48, 60, 80]
    labels = ['< 1 Year', '1-2 Years', '2-4 Years', '4-5 Years', '> 5 Years']

    data['tenure_binning'] = pd.cut(data['tenure'], bins=binnings, labels=labels, include_lowest=True)

    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])

    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
        ('encoder', OneHotEncoder(handle_unknown='ignore'))
    ])

    ordinal_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('encoder', OrdinalEncoder(categories=[labels]))
    ])

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features),
            ('ord', ordinal_transformer, ordinal_features)
        ]
    )

    data = pd.DataFrame(preprocessor.fit_transform(data), columns=preprocessor.get_feature_names_out())
    data.to_csv(file_path, index=False)
    print(f"Data berhasil disimpan ke: {file_path}")

    X = data.drop(columns=[target_column])
    y = data[target_column]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    X_train = preprocessor.fit_transform(X_train)
    X_test = preprocessor.transform(X_test)

    dump(preprocessor, save_path)

    return X_train, X_test, y_train, y_test

target_column = 'Churn'
save_path = 'preprocessing/preprocessor_pipeline.joblib'
file_path = 'preprocessing/data.csv'
final_dataset_path = 'preprocessing/WA_Fn-UseC_-Telco-Customer-Churn_preprocessing.csv'

if __name__ == "__main__":
    csv_file = "WA_Fn-UseC_-Telco-Customer-Churn.csv"

    df = pd.read_csv(csv_file)

    X_train, X_test, y_train, y_test = preprocess_data(df, target_column, save_path, file_path, final_dataset_path)

    print("Preprocess Done")